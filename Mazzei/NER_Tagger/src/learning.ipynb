{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         POSITION      WORD TAG\n",
      "0               0      This   O\n",
      "1               1  division   O\n",
      "2               2      also   O\n",
      "3               3  contains   O\n",
      "4               4       the   O\n",
      "...           ...       ...  ..\n",
      "2193674        27      born   O\n",
      "2193675        28         1   O\n",
      "2193676        29       May   O\n",
      "2193677        30      1964   O\n",
      "2193678        31         .   O\n",
      "\n",
      "[2193679 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "# function to read data from file\n",
    "def read_dataset(file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name+\".conllu\"\n",
    "    data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return data\n",
    "\n",
    "train_data=read_dataset(\"train\",\"en\")\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING:\n",
    "### Counting\n",
    "- word_tag_counts = number of times a word is associated with each tag\n",
    "- tag_tag_counts =  number of times a tag is followed by another tag    (also considering an extra tag \"START\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_occurence(train_data):\n",
    "  tag_list=train_data['TAG'].unique()\n",
    "  word_list=train_data['WORD'].unique()\n",
    "  empty_tag_count_dict= {tag:0 for tag in tag_list}\n",
    "\n",
    "  tag_counts = empty_tag_count_dict.copy()  # {tag1:0, tag2:0, ...}\n",
    "  word_tag_counts = {word:empty_tag_count_dict.copy() for word in word_list} # {word1:{tag1:0, tag2:0, ...}, word2:{tag1:0, tag2:0, ...}, ...}\n",
    "  tag_tag_counts = {tag:empty_tag_count_dict.copy() for tag in tag_list} # {tag1:{tag1:0, tag2:0, ...}, tag2:{tag1:0, tag2:0, ...}, ...}\n",
    "  #tag_tag_counts['START'] = empty_tag_count_dict.copy()\n",
    "  #tag_counts['START'] = 0\n",
    " \n",
    "\n",
    "  for index, row in train_data.iterrows():\n",
    "      word = row['WORD']\n",
    "      tag = row['TAG']\n",
    "      pos= row['POSITION']\n",
    "      \n",
    "      if pos!=0:\n",
    "        tag_tag_counts[prev_tag][tag] +=1\n",
    "\n",
    "      \n",
    "      tag_counts[tag] += 1\n",
    "      word_tag_counts[word][tag] +=1\n",
    "      prev_tag = tag\n",
    "\n",
    "  \n",
    "  return tag_counts, word_tag_counts, tag_tag_counts\n",
    "\n",
    "tag_counts, word_tag_counts, tag_tag_counts= counts_occurence(train_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities\n",
    "- emission_prob = probability, given a tag, that it will be associated with a given word\n",
    "- transition_prob = probability of a tag occurring given the previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probs(tag_counts, word_tag_counts, tag_tag_counts):\n",
    "    tag_list = list(tag_counts.keys())\n",
    "    word_list = list(word_tag_counts.keys())\n",
    "\n",
    "    emission_prob = {word: {} for word in word_list} \n",
    "    transition_prob = {tag: {} for tag in tag_list} \n",
    "\n",
    "    # Calcolo delle probabilità di emissione\n",
    "    for word, tag_dict in word_tag_counts.items():\n",
    "        total_tag_count = sum(tag_dict.values())\n",
    "        for tag, count in tag_dict.items():\n",
    "            emission_prob[word][tag] = count / total_tag_count if total_tag_count > 0 else 0\n",
    "\n",
    "    # Calcolo delle probabilità di transizione\n",
    "    for prev, tag_dict in tag_tag_counts.items():\n",
    "        total_tag_count = tag_counts[prev]\n",
    "        for next_tag, count in tag_dict.items():\n",
    "            transition_prob[prev][next_tag] = count / total_tag_count if total_tag_count > 0 else 0\n",
    "\n",
    "    return emission_prob, transition_prob\n",
    "\n",
    "emission_prob, transition_prob= calculate_probs(tag_counts, word_tag_counts, tag_tag_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize data into a file \n",
    "def save_data(data,file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file= open(path, 'wb') \n",
    "        pickle.dump(data, file) \n",
    "        file.close() \n",
    "    except: \n",
    "        print(\"Error in writing data\")\n",
    "\n",
    "# save_data(transition_prob,\"transition_prob\",\"it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learn emission and transition probabilities for each language\n",
    "for language in [\"en\",\"it\",\"es\"]:\n",
    "    read_dataset(\"train\",language)\n",
    "    tag_counts, word_tag_counts, tag_tag_counts= counts_occurence(train_data)\n",
    "    emission_prob, transition_prob= calculate_probs(tag_counts, word_tag_counts, tag_tag_counts)\n",
    "    save_data(transition_prob,\"transition_prob\",language)\n",
    "    save_data(emission_prob,\"emission_prob\",language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAUTenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
