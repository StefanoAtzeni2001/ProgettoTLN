{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "# function to read data from file\n",
    "def read_dataset(file_name,language):\n",
    "    path=\"../data/\"+language+\"/dataset/\"+file_name+\".conllu\"\n",
    "    data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#serialize data into a file \n",
    "def save_data(data,file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file= open(path, 'wb') \n",
    "        pickle.dump(data, file) \n",
    "        file.close() \n",
    "    except: \n",
    "        print(\"Error in writing data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Counteggio\n",
    "- word_tag_counts = numero di occorenze in cui una parola è associata ad un certo tag\n",
    "- tag_tag_counts =  numero di occroenze in cui un tag è seguito da un certo tag   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_occurence(train_data):\n",
    "  tag_list=train_data['TAG'].unique()\n",
    "  word_list=train_data['WORD'].unique()\n",
    "  empty_tag_count_dict= {tag:0 for tag in tag_list}\n",
    "\n",
    "  tag_counts = empty_tag_count_dict.copy()  # {tag1:0, tag2:0, ...}\n",
    "  word_tag_counts = {word:empty_tag_count_dict.copy() for word in word_list} # {word1:{tag1:0, tag2:0, ...}, word2:{tag1:0, tag2:0, ...}, ...}\n",
    "  tag_tag_counts = {tag:empty_tag_count_dict.copy() for tag in tag_list} # {tag1:{tag1:0, tag2:0, ...}, tag2:{tag1:0, tag2:0, ...}, ...}\n",
    "  #tag_tag_counts['START'] = empty_tag_count_dict.copy()\n",
    "  #tag_counts['START'] = 0\n",
    "  \n",
    "  for index, row in train_data.iterrows():\n",
    "      word = row['WORD']\n",
    "      tag = row['TAG']\n",
    "      pos= row['POSITION']\n",
    "      \n",
    "      if pos!=0:\n",
    "        tag_tag_counts[prev_tag][tag] +=1\n",
    "\n",
    "      tag_counts[tag] += 1\n",
    "      word_tag_counts[word][tag] +=1\n",
    "      prev_tag = tag\n",
    "\n",
    "  return tag_counts, word_tag_counts, tag_tag_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilità\n",
    "- emission_prob = $p(w_i|t_i)$: probabilità, dato un tag, che venga associato ad una certa parola  \n",
    "- transition_prob = $p(t_i|t_{i-1})$: probabilità di occorenza di un tag dato il tag precedente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probs(tag_counts, word_tag_counts, tag_tag_counts):\n",
    "    tag_list = list(tag_counts.keys())\n",
    "    word_list = list(word_tag_counts.keys())\n",
    "\n",
    "    emission_prob = {word: {} for word in word_list} \n",
    "    transition_prob = {tag: {} for tag in tag_list} \n",
    "\n",
    "    # Calcolo delle probabilità di emissione\n",
    "    for word, tag_dict in word_tag_counts.items():\n",
    "        total_tag_count = sum(tag_dict.values())\n",
    "        for tag, count in tag_dict.items():\n",
    "            emission_prob[word][tag] = count / total_tag_count if total_tag_count > 0 else 0\n",
    "\n",
    "    # Calcolo delle probabilità di transizione\n",
    "    for prev, tag_dict in tag_tag_counts.items():\n",
    "        total_next_tag_count = sum(tag_dict.values())\n",
    "        for next_tag, count in tag_dict.items():\n",
    "            transition_prob[prev][next_tag] = count / total_next_tag_count if total_next_tag_count > 0 else 0\n",
    "\n",
    "    return emission_prob, transition_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_probabilities(emission_prob, transition_prob):\n",
    "    # Verifica delle probabilità di emissione\n",
    "    for word, tag_dict in emission_prob.items():\n",
    "        total_emission_prob = sum(tag_dict.values())\n",
    "        if abs(total_emission_prob - 1) > 1e-6:\n",
    "            print(f\"WARNING: La somma delle probabilità di emissione per la parola '{word}' non è 1, ma {total_emission_prob}\")\n",
    "\n",
    "    # Verifica delle probabilità di transizione\n",
    "    for tag, next_tag_dict in transition_prob.items():\n",
    "        total_transition_prob = sum(next_tag_dict.values())\n",
    "        if abs(total_transition_prob - 1) > 1e-6:\n",
    "            print(f\"WARNING: La somma delle probabilità di transizione per il tag '{tag}' non è 1, ma {total_transition_prob}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcola la probabilità di emissione di un tag per le parole  \"sconosciute\"\n",
    "#usando il dataset di validazione e considerando le parole che appaiono una sola volta\n",
    "def calculate_unknown_probs(val_data):\n",
    "\n",
    "    word_counts = val_data['WORD'].value_counts()\n",
    "    unique_rows = val_data[val_data['WORD'].map(word_counts) == 1]\n",
    "    tag_counts= unique_rows['TAG'].value_counts()\n",
    "    tag_list=val_data['TAG'].unique()\n",
    "    unknown_prob= {tag:0 for tag in tag_list}\n",
    "\n",
    "    for tag in tag_list:\n",
    "        if tag not in unknown_prob:\n",
    "            unknown_prob[tag] = 0\n",
    "        else:\n",
    "            unknown_prob[tag] = tag_counts[tag]/sum(tag_counts)\n",
    "    return unknown_prob\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impara le probabilità di transizione, di emissione per le lingue en, it, es\n",
    "for language in [\"en\",\"it\",\"es\"]:\n",
    "    train_data=read_dataset(\"train\",language)\n",
    "    tag_counts, word_tag_counts, tag_tag_counts= counts_occurence(train_data)\n",
    "    emission_prob, transition_prob= calculate_probs(tag_counts, word_tag_counts, tag_tag_counts)\n",
    "    check_probabilities(emission_prob, transition_prob)\n",
    "    save_data(transition_prob,\"transition_prob\",language)\n",
    "    save_data(emission_prob,\"emission_prob\",language)\n",
    "    val_data=read_dataset(\"val\",language)\n",
    "    unknown_prob=calculate_unknown_probs(val_data)\n",
    "    save_data(unknown_prob,\"unknown_prob\",language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAUTenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
