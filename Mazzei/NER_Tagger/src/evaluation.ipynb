{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# function to read data from file\n",
    "def read_tagging(file_name,language):\n",
    "    path=\"../data/\"+language+\"/tagging/\"+file_name+\".conllu\"\n",
    "    data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_sentences_from_dataframe(df):\n",
    "    sentences = ''\n",
    "    for index, row in df.iterrows():\n",
    "        word = row['WORD']\n",
    "        if pd.notnull(word):  # Se la parola non è nulla\n",
    "            if sentences:  # Se c'è già una frase, aggiungi uno spazio prima della nuova parola\n",
    "                sentences += ' '\n",
    "            sentences += word\n",
    "    return sentences\n",
    "\n",
    "#deserialize data from a file\n",
    "def load_data(file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file = open(path, 'rb') \n",
    "        data = pickle.load(file) \n",
    "        return data\n",
    "    except: \n",
    "        print(\"Error in reading data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_entities_from_dataframe(dataframe):\n",
    "    entity_spans = []\n",
    "\n",
    "    current_entity_span = None\n",
    "    current_sentence_index = 0\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        word = row['WORD']\n",
    "        tag = row['TAG']\n",
    "        position = row['POSITION']\n",
    "\n",
    "        if position == 0:  # Inizio di una nuova frase\n",
    "            current_sentence_index += 1\n",
    "\n",
    "        if tag != 'O':\n",
    "            if tag.startswith('B-'):\n",
    "                # Se inizia una nuova entità, chiudi quella corrente e inizia una nuova\n",
    "                if current_entity_span is not None:\n",
    "                    entity_spans.append(current_entity_span)\n",
    "                current_entity_span = {'Tag': tag[2:], 'Sentence Number': current_sentence_index}\n",
    "                current_entity_span['Start Index'] = index\n",
    "                current_entity_span['End Index'] = index\n",
    "            elif tag.startswith('I-'):\n",
    "                # Aggiungi la parola all'entità corrente\n",
    "                if current_entity_span is not None:\n",
    "                    current_entity_span['End Index'] = index\n",
    "            else:\n",
    "                print(\"Errore: Tag non riconosciuto.\")\n",
    "\n",
    "        else:\n",
    "            # Se il tag è \"O\" ma siamo all'interno di una serie di tag non \"O\", chiudi l'entità corrente\n",
    "            if current_entity_span is not None:\n",
    "                entity_spans.append(current_entity_span)\n",
    "                current_entity_span = None\n",
    "\n",
    "    # Aggiungi l'ultima entità se presente\n",
    "    if current_entity_span is not None:\n",
    "        entity_spans.append(current_entity_span)\n",
    "\n",
    "    # Creazione del dataframe di output\n",
    "    output_data = {'Tag': [], 'Sentence Number': [], 'Start Index': [], 'End Index': []}\n",
    "    for entity_span in entity_spans:\n",
    "        output_data['Tag'].append(entity_span['Tag'])\n",
    "        output_data['Sentence Number'].append(entity_span['Sentence Number'])\n",
    "        output_data['Start Index'].append(entity_span['Start Index'])\n",
    "        output_data['End Index'].append(entity_span['End Index'])\n",
    "\n",
    "    output_df = pd.DataFrame(output_data)\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_accuracy(system_df, golden_df):\n",
    "    # Uniamo i due dataframe per confrontare i tag\n",
    "    merged_df = pd.merge(system_df, golden_df, left_index=True, right_index=True, suffixes=('_system', '_golden'))\n",
    "    \n",
    "    # Contiamo quante volte i tag corrispondenti sono uguali\n",
    "    correct_tags = (merged_df['TAG_system'] == merged_df['TAG_golden']).sum()\n",
    "    \n",
    "    # Calcoliamo l'accuratezza\n",
    "    accuracy = correct_tags / len(system_df)\n",
    "    \n",
    "    # Converti in percentuale e arrotonda alla prima cifra decimale\n",
    "    accuracy_percent = round(accuracy * 100, 1)\n",
    "    \n",
    "    return accuracy_percent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_precision_recall(predicted_df, golden_df):\n",
    "    # Unione delle entità predette e delle entità del sistema dorato\n",
    "    merged_df = pd.merge(predicted_df, golden_df, how='outer', indicator=True)\n",
    "\n",
    "    # Calcolo dei true positives (TP), false positives (FP) e false negatives (FN)\n",
    "    TP = merged_df[(merged_df['_merge'] == 'both')].shape[0]\n",
    "    FP = merged_df[(merged_df['_merge'] == 'right_only')].shape[0]\n",
    "    FN = merged_df[(merged_df['_merge'] == 'left_only')].shape[0]\n",
    "\n",
    "    # Calcolo della precisione e del recall\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    print(\"TP:\",TP,\"FP:\",FP,\"FN:\",FN)\n",
    "    # Converti in percentuali e arrotonda alla prima cifra decimale\n",
    "    precision_percent = round(precision * 100, 1)\n",
    "    recall_percent = round(recall * 100, 1)\n",
    "\n",
    "    return precision_percent, recall_percent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 3 FP: 736 FN: 846\n",
      "TP: 389 FP: 350 FN: 562\n",
      "TP: 7 FP: 685 FN: 528\n",
      "TP: 417 FP: 275 FN: 514\n",
      "TP: 4 FP: 668 FN: 358\n",
      "TP: 404 FP: 268 FN: 486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def evaluate_and_save_results(languages, output_file, dataset_size, smoothing_type):\n",
    "\n",
    "    # Scrivi i risultati su file\n",
    "   \n",
    "    with open(output_file, \"a\") as file:\n",
    "        file.write(\"##################################\\n\")\n",
    "        file.write(f\"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        file.write(f\"Dimensione del dataset: {dataset_size}\\n\")\n",
    "        file.write(f\"Tipo di Smoothing: {'Smoothing Type ' + str(smoothing_type)}\\n\\n\")\n",
    "        file.write(\"Statistiche aggiuntive:\\n\")\n",
    "        file.write(\"Language ||| Acc Naive | Precision Naive | Recall Naive ||| Acc Viterbi| Precision Viterbi| Recall Viterbi\\n\")\n",
    "        \n",
    "        for language in languages:\n",
    "            vit_df= read_tagging(\"sent_viterbi_tag\", language)\n",
    "            naive_df = read_tagging(\"naive_tag\", language)\n",
    "            golden_df = read_tagging(\"golden_tag\", language)\n",
    "            \n",
    "            gold_quadruples_df = extract_entities_from_dataframe(golden_df)\n",
    "            naive_quadruples_df = extract_entities_from_dataframe(naive_df)\n",
    "            vit_quadruples_df = extract_entities_from_dataframe(vit_df)\n",
    "            \n",
    "\n",
    "         \n",
    "            acc_vit= calculate_accuracy(vit_df, golden_df)\n",
    "            acc_naive = calculate_accuracy(naive_df, golden_df)\n",
    "            precision_vit, recall_vit = calculate_precision_recall(vit_quadruples_df, gold_quadruples_df)\n",
    "            precision_n, recall_n = calculate_precision_recall(naive_quadruples_df, gold_quadruples_df)\n",
    "\n",
    "            file.write(f\"{language} ||| {format(acc_naive, '.1f')} % | {format(precision_n, '.1f')} % | {format(recall_n, '.1f')} % ||| {format(acc_vit, '.1f')} % | {format(precision_vit, '.1f')} % | {format(recall_vit, '.1f')} % |\\n\")\n",
    "        \n",
    "        file.write(\"##################################\\n \\n\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "languages = [\"en\", \"it\", \"es\"]\n",
    "output_file = \"../evaluation_results.txt\"\n",
    "dataset_size = 100\n",
    "smoothing_type = 4\n",
    "evaluate_and_save_results(languages, output_file, dataset_size, smoothing_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
