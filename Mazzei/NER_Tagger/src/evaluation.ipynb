{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# function to read data from file\n",
    "def read_tagging(file_name,language):\n",
    "    path=\"../data/\"+language+\"/tagging/\"+file_name+\".conllu\"\n",
    "    data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_dataset_memm(file_name,language):\n",
    "    filename=\"../data/\"+language+\"/dataset/\"+file_name+\".conllu\"\n",
    "    #data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo una funzione per estrarre le entità nominate da una frase\n",
    "def extract_entities(sentence):\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    for idx, (word, tag) in enumerate(sentence):\n",
    "        if tag.startswith('B-'):\n",
    "            if current_entity is not None:\n",
    "                entities.append(current_entity)\n",
    "            current_entity = {'type': tag[2:], 'start': idx, 'end': idx, 'words': [word]}\n",
    "        elif tag.startswith('I-'):\n",
    "            if current_entity is not None:\n",
    "                current_entity['end'] = idx\n",
    "                current_entity['words'].append(word)\n",
    "        else:\n",
    "            if current_entity is not None:\n",
    "                entities.append(current_entity)\n",
    "                current_entity = None\n",
    "    if current_entity is not None:\n",
    "        entities.append(current_entity)\n",
    "    return entities\n",
    "\n",
    "# Definiamo una funzione per dividere il testo in frasi\n",
    "def split_into_sentences(text):\n",
    "    return re.split(r'(?<=[.!?]) +', text)\n",
    "\n",
    "# Definiamo una funzione per creare le quadruple\n",
    "def create_quadruples(sentence, entities, sentence_idx):\n",
    "    quadruples = []\n",
    "    for entity in entities:\n",
    "        quadruples.append((entity['type'], f\"sent-{sentence_idx}\", entity['start'], entity['end'], ' '.join(entity['words'])))\n",
    "    return quadruples\n",
    "\n",
    "# Funzione che dato in ingresso un dataframe di tipo (POSITION - WORD - TAG) \n",
    "#mi restituisce un DataFrame delle Entità espresse in quadruple\n",
    "def process_dataframe(df):\n",
    "    quadruples = []\n",
    "    current_sentence = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if isinstance(row['WORD'], float):\n",
    "            # Convertiamo il float in una stringa\n",
    "            word = str(row['WORD'])\n",
    "        else:\n",
    "            word = row['WORD']\n",
    "            \n",
    "        if word in ('.', '!', '?'):\n",
    "            current_sentence.append((word, row['TAG']))\n",
    "            entities = extract_entities(current_sentence)\n",
    "            quadruples.extend(create_quadruples(current_sentence, entities, len(quadruples) + 1))\n",
    "            current_sentence = []\n",
    "        else:\n",
    "            current_sentence.append((word, row['TAG']))\n",
    "    quadruples_df = pd.DataFrame(quadruples, columns=['TAG', 'Contesto', 'Indice_inizio', 'Indice_fine', 'Entità'])\n",
    "    return quadruples_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo una funzione per calcolare l'accuratezza dei singoli tag, vuole in ingresso i dataframe \"classici\" (POSITION -WORD -TAG)\n",
    "\n",
    "def calculate_accuracy(system_df, golden_df):\n",
    "    # Uniamo i due dataframe per confrontare i tag\n",
    "    merged_df = pd.merge(system_df, golden_df, left_index=True, right_index=True, suffixes=('_system', '_golden'))\n",
    "    \n",
    "    # Contiamo quante volte i tag corrispondenti sono uguali\n",
    "    correct_tags = (merged_df['TAG_system'] == merged_df['TAG_golden']).sum()\n",
    "    \n",
    "    # Calcoliamo l'accuratezza\n",
    "    accuracy = correct_tags / len(system_df)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(predicted_df, golden_df):\n",
    "    # Effettuiamo il merge esterno tra i due dataframe\n",
    "    merged_df = predicted_df.merge(golden_df, how='outer', on=['Entità'], suffixes=('_pred', '_gold'))\n",
    "    \n",
    "    # Contiamo il numero totale di corrispondenze esatte (True Positives)\n",
    "    correct_matches = ((merged_df['TAG_pred'] == merged_df['TAG_gold']) & \n",
    "                       (merged_df['Contesto_pred'] == merged_df['Contesto_gold']) &\n",
    "                       (merged_df['Indice_inizio_pred'] == merged_df['Indice_inizio_gold']) &\n",
    "                       (merged_df['Indice_fine_pred'] == merged_df['Indice_fine_gold'])).sum()\n",
    "\n",
    "    # Calcoliamo il numero di False Positives (FP) e False Negatives (FN)\n",
    "    false_positives = merged_df['TAG_gold'].isna().sum()\n",
    "    false_negatives = merged_df['TAG_pred'].isna().sum()\n",
    "\n",
    "    # Calcoliamo precisione e richiamo\n",
    "    precision = correct_matches / (correct_matches + false_positives) if (correct_matches + false_positives) > 0 else 0\n",
    "    recall = correct_matches / (correct_matches + false_negatives) if (correct_matches + false_negatives) > 0 else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********Number of features: 1157494**********\n",
      "fit model...\n",
      "Development Accuracy: 0.964 (592.0/614.0).\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m memm_data \u001b[38;5;241m=\u001b[39m memm_tagger\u001b[38;5;241m.\u001b[39mload_data(read_dataset_memm(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      8\u001b[0m memm_tag \u001b[38;5;241m=\u001b[39m memm_tagger\u001b[38;5;241m.\u001b[39mtrain(read_dataset_memm(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit\u001b[39m\u001b[38;5;124m\"\u001b[39m),memm_data)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmemm_tagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_dataset_memm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemm_tag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmemm_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m nay_quadruples_df \u001b[38;5;241m=\u001b[39m process_dataframe(nayve_df)\n\u001b[0;32m     13\u001b[0m vit_quadruples_df \u001b[38;5;241m=\u001b[39m process_dataframe(Vit_df)\n",
      "File \u001b[1;32mc:\\Users\\User\\OneDrive\\Desktop\\2.1 [TNL] Linguaggio naturale\\Progetti\\ProgettoTLN\\Mazzei\\NER_Tagger\\src\\memm_tagger.py:356\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(filename, log_reg, data)\u001b[0m\n\u001b[0;32m    352\u001b[0m                 X[\u001b[38;5;241m0\u001b[39m, feature_vocab[feat]] \u001b[38;5;241m=\u001b[39m feats[feat]\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;66;03m# update Y_pred with the probabilities of all current tags\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;66;03m# given the current word, previous tag and other data/feature\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m         prob \u001b[38;5;241m=\u001b[39m \u001b[43mlog_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m         Y_pred[j, label_vocab[possible_previous_tag]] \u001b[38;5;241m=\u001b[39m prob\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# decode to get the predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:1386\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_predict_proba_lr(X)\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1386\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decision\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;66;03m# Workaround for multi_class=\"multinomial\" and binary outcomes\u001b[39;00m\n\u001b[0;32m   1389\u001b[0m         \u001b[38;5;66;03m# which requires softmax prediction with only a 1D decision.\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m         decision_2d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[\u001b[38;5;241m-\u001b[39mdecision, decision]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_base.py:433\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 433\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    190\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    195\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m ):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_base.py:624\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_base.py:526\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(other\u001b[38;5;241m.\u001b[39mravel())\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[1;32m--> 526\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_multivector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\sparse\\_compressed.py:502\u001b[0m, in \u001b[0;36m_cs_matrix._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[0;32m    500\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    501\u001b[0m fn(M, N, n_vecs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m--> 502\u001b[0m    other\u001b[38;5;241m.\u001b[39mravel(), result\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import memm_tagger\n",
    "Vit_df=read_tagging(\"viterbi_tag\",\"it\")\n",
    "nayve_df=read_tagging(\"nayve_tag\",\"it\")\n",
    "golden_df=read_tagging(\"golden_tag\",\"it\")\n",
    "\n",
    "\n",
    "memm_data = memm_tagger.load_data(read_dataset_memm(\"train\",\"it\"))\n",
    "memm_tag = memm_tagger.train(read_dataset_memm(\"train\",\"it\"),memm_data)\n",
    "memm_tagger.test(read_dataset_memm(\"test\",\"it\"),memm_tag,memm_data)\n",
    "\n",
    "\n",
    "nay_quadruples_df = process_dataframe(nayve_df)\n",
    "vit_quadruples_df = process_dataframe(Vit_df)\n",
    "gol_quadruples_df = process_dataframe(golden_df)\n",
    "\n",
    "acc_vit=calculate_accuracy(Vit_df,golden_df)\n",
    "acc_nayve=calculate_accuracy(nayve_df,golden_df)\n",
    "precision_v, recall_v =calculate_precision_recall(vit_quadruples_df,gol_quadruples_df)\n",
    "precision_n, recall_n =calculate_precision_recall(nay_quadruples_df,gol_quadruples_df)\n",
    "\n",
    "print(\"Accuracy Viterbi:\"+ format(acc_vit))\n",
    "print(\"Accuracy nayve:\"+ format(acc_vit))\n",
    "print(\"\\n\")\n",
    "print(\"precision viterbi:\"+ format(precision_v))\n",
    "print(\"recall viterbi:\"+ format(recall_v))\n",
    "print(\"\\n\")\n",
    "print(\"precision nayve:\"+ format(precision_n))\n",
    "print(\"recall nayve:\"+ format(recall_n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
