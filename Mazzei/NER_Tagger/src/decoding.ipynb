{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#deserialize data from a file\n",
    "def load_data(file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file = open(path, 'rb') \n",
    "        data = pickle.load(file) \n",
    "        return data\n",
    "    except: \n",
    "        print(\"Error in reading data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from conllu import parse, TokenList\n",
    "\n",
    "# Funzione per salvare il DataFrame in un file CoNLL-U\n",
    "def save_to_conllu(dataframe,file_name,language):\n",
    "    # Creazione della lista di token da DataFrame\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    tokens = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        token = {\n",
    "            \"id\": row['POSITION'],\n",
    "            \"form\": row['WORD'],\n",
    "            \"misc\":  row['TAG']\n",
    "        }\n",
    "        tokens.append(token)\n",
    "    \n",
    "    # Creazione dell'oggetto TokenList\n",
    "    token_list = TokenList(tokens)\n",
    "    \n",
    "    # Scrittura del TokenList nel file CoNLL-U\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(token_list.serialize())\n",
    "    print(\"DataFrame salvato in formato CoNLL-U:\", path)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "\n",
    "#save_to_conllu(df, \"output.conllu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Funzione per l'algoritmo di Viterbi: prende in input le probabilità di emissione e di transizione sottoforma di dataframe\n",
    "# e restituisce le coppie parola-NER_TAG assegnate\n",
    "def Viterbi(emission_dataframe, transition_dataframe):\n",
    "    epsilon = 1e-10  # Valore molto piccolo\n",
    "    # Lista delle parole nel testo\n",
    "    testo_array = emission_dataframe.columns.tolist()\n",
    "    # Numero di stati (tag)\n",
    "    K = transition_dataframe.shape[0]\n",
    "    \n",
    "    # Lunghezza del testo\n",
    "    T = len(testo_array)\n",
    "    \n",
    "    # Inizializzazione\n",
    "    viterbi = np.zeros((K, T))\n",
    "    backpointer = np.zeros((K, T), dtype=int)\n",
    "    \n",
    "    # Inizializzazione del primo passo\n",
    "    Pi = 1  # Start equiprobabile \n",
    "    viterbi[:, 0] = np.log(emission_dataframe.iloc[:, 0] + epsilon) + np.log(Pi)\n",
    "    backpointer[:, 0] = 0 \n",
    "    \n",
    "    # Iterazione\n",
    "    for t in range(1, T):\n",
    "        for k in range(K):\n",
    "            # Calcolo della probabilità Viterbi per ogni stato\n",
    "            max_val = float('-inf')\n",
    "            max_idx = 0\n",
    "            for j in range(K):\n",
    "                val = viterbi[j, t - 1] + np.log(transition_dataframe.iloc[j, k] + epsilon) + np.log(emission_dataframe.iloc[k, t] + epsilon)\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    max_idx = j\n",
    "            viterbi[k, t] = max_val\n",
    "            backpointer[k, t] = max_idx\n",
    "    \n",
    "    # Terminazione: Trova il massimo della colonna finale\n",
    "    max_final_val = np.max(viterbi[:, T - 1])\n",
    "    max_final_idx = np.argmax(viterbi[:, T - 1])\n",
    "    \n",
    "    # Costruzione del percorso Viterbi partendo dall'ultimo passo\n",
    "    viterbi_path = [max_final_idx]\n",
    "    for i in reversed(range(1, T)):\n",
    "        viterbi_path.insert(0, backpointer[viterbi_path[0], i])\n",
    "    \n",
    "    # Costruzione delle coppie parola-tag assegnate\n",
    "    word_tag_pairs = [(testo_array[i], transition_dataframe.index[j]) for i, j in enumerate(viterbi_path)]\n",
    "    \n",
    "    # Stampa del percorso Viterbi e delle coppie parola-tag assegnate\n",
    "    print(\"Percorso Viterbi:\", viterbi_path)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'POSITION': range(1, T + 1),\n",
    "        'WORD': [pair[0] for pair in word_tag_pairs],\n",
    "        'TAG': [pair[1] for pair in word_tag_pairs]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione del sub-dataset di probabilità di emissione per le parole di una frase.\n",
    "\n",
    "Applicazione di diverse tecniche di smoothing per gestire le parole sconosciute:\n",
    "\n",
    "1 - Sempre O: P(unk|O) = 1\n",
    "\n",
    "2 - Sempre O o MISC: P(unk|O)=P(unk|B-MISC)=0.5\n",
    "\n",
    "3 - Uniforme: P(unk|tag) = 1/#(NER_TAGs)\n",
    "\n",
    "4 - Statistica TAG sul val set: parole che compaiono 1 sola volta  -> unknown_prob calcolata nel file learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prende in input una frase, le probabilità di emisione e transizione apprese \n",
    "#restituisce le coppie parola-NER_TAG assegnate utilizzano l'algoritmo di Viterbi e applicando la tecnica di smoothing specificata\n",
    "def viterbi_tagger(sentence, emission_prob, transition_prob, smoothing_type=1):\n",
    "    #inizializzazione\n",
    "    tags=transition_prob.keys()\n",
    "    words = sentence.split()\n",
    "    transition_df = pd.DataFrame.from_dict(transition_prob)\n",
    "    emission_sentence_df = pd.DataFrame(columns=words,index=tags)\n",
    "    \n",
    "    #iterazione per ogni parola delle frase aggiorna il dataframe delle emissioni\n",
    "    for word in words:\n",
    "        if word in emission_prob:\n",
    "            emission_sentence_df[word] = emission_prob[word].values()\n",
    "        else: #applicazione dello smoothing\n",
    "            if (smoothing_type==1): emission_sentence_df[word] =  {tag: 1 if tag == \"O\" else 0 for tag in tags}\n",
    "            elif (smoothing_type==2): emission_sentence_df[word] =  {tag: 0.5 if tag == \"B-MISC\" or tag == \"O\" else 0 for tag in tags}\n",
    "            elif (smoothing_type==3): emission_sentence_df[word] =  {tag: 1/len(tags) for tag in tags}\n",
    "            elif (smoothing_type==4): emission_sentence_df[word] =  unkown_prob\n",
    "   \n",
    "    return Viterbi(emission_sentence_df, transition_df)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "#caricamento delle probabilità apprese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percorso Viterbi: [0, 0, 0, 0, 0, 0, 8, 8, 8, 8, 5, 0, 7, 6, 0, 0]\n",
      "    POSITION               WORD    TAG\n",
      "0          1                The      O\n",
      "1          2  PAROLASCONOSCIUTA      O\n",
      "2          3               tour      O\n",
      "3          4              would      O\n",
      "4          5              cover      O\n",
      "5          6                the      O\n",
      "6          7             United  I-ORG\n",
      "7          8             States  I-ORG\n",
      "8          9                and  I-ORG\n",
      "9         10                the  I-ORG\n",
      "10        11                 UK  B-ORG\n",
      "11        12                and      O\n",
      "12        13            Ireland  I-PER\n",
      "13        14         throughout  B-PER\n",
      "14        15               2019      O\n",
      "15        16                  .      O\n",
      "DataFrame salvato in formato CoNLL-U: ../data/it/viterbi_tag.conllu\n"
     ]
    }
   ],
   "source": [
    "emission_prob=load_data(\"emission_prob\",\"it\")\n",
    "transition_prob=load_data(\"transition_prob\",\"it\")\n",
    "unkown_prob=load_data(\"unknown_prob\",\"it\")\n",
    "sentence = \"The PAROLASCONOSCIUTA tour would cover the United States and the UK and Ireland throughout 2019 .\"\n",
    "vit_df=viterbi_tagger(sentence,emission_prob,transition_prob,4)\n",
    "print(vit_df)\n",
    "save_to_conllu(vit_df, \"viterbi_tag.conllu\", \"it\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TLNenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
