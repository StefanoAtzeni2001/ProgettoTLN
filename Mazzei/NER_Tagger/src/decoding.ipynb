{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "#deserialize data from a file\n",
    "def load_data(file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file = open(path, 'rb') \n",
    "        data = pickle.load(file) \n",
    "        return data\n",
    "    except: \n",
    "        print(\"Error in reading data\")\n",
    "\n",
    "#caricamento delle probabilità apprese\n",
    "emission_prob=load_data(\"emission_prob\",\"en\")\n",
    "transition_prob=load_data(\"transition_prob\",\"en\")\n",
    "unkown_prob=load_data(\"unknown_prob\",\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Funzione per l'algoritmo di Viterbi: prende in input le probabilità di emissione e di transizione sottoforma di dataframe\n",
    "# e restituisce le coppie parola-NER_TAG assegnate\n",
    "def Viterbi(emission_dataframe, transition_dataframe):\n",
    "    epsilon = 1e-10  # Valore molto piccolo\n",
    "    # Lista delle parole nel testo\n",
    "    testo_array = emission_dataframe.columns.tolist()\n",
    "    # Numero di stati (tag)\n",
    "    K = transition_dataframe.shape[0]\n",
    "    \n",
    "    # Lunghezza del testo\n",
    "    T = len(testo_array)\n",
    "    \n",
    "    # Inizializzazione\n",
    "    viterbi = np.zeros((K, T))\n",
    "    backpointer = np.zeros((K, T), dtype=int)\n",
    "    \n",
    "    # Inizializzazione del primo passo\n",
    "    Pi = 1  # Start equiprobabile \n",
    "    viterbi[:, 0] = np.log(emission_dataframe.iloc[:, 0] + epsilon) + np.log(Pi)\n",
    "    backpointer[:, 0] = 0 \n",
    "    \n",
    "    # Iterazione\n",
    "    for t in range(1, T):\n",
    "        for k in range(K):\n",
    "            # Calcolo della probabilità Viterbi per ogni stato\n",
    "            max_val = float('-inf')\n",
    "            max_idx = 0\n",
    "            for j in range(K):\n",
    "                val = viterbi[j, t - 1] + np.log(transition_dataframe.iloc[j, k] + epsilon) + np.log(emission_dataframe.iloc[k, t] + epsilon)\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    max_idx = j\n",
    "            viterbi[k, t] = max_val\n",
    "            backpointer[k, t] = max_idx\n",
    "    \n",
    "    # Terminazione: Trova il massimo della colonna finale\n",
    "    max_final_val = np.max(viterbi[:, T - 1])\n",
    "    max_final_idx = np.argmax(viterbi[:, T - 1])\n",
    "    \n",
    "    # Costruzione del percorso Viterbi partendo dall'ultimo passo\n",
    "    viterbi_path = [max_final_idx]\n",
    "    for i in reversed(range(1, T)):\n",
    "        viterbi_path.insert(0, backpointer[viterbi_path[0], i])\n",
    "    \n",
    "    # Costruzione delle coppie parola-tag assegnate\n",
    "    word_tag_pairs = [(testo_array[i], transition_dataframe.index[j]) for i, j in enumerate(viterbi_path)]\n",
    "    \n",
    "    # Stampa del percorso Viterbi e delle coppie parola-tag assegnate\n",
    "    print(\"Percorso Viterbi:\", viterbi_path)\n",
    "    print(\"Coppie parola-tag assegnate:\", word_tag_pairs)\n",
    "    \n",
    "    return word_tag_pairs\n",
    "\n",
    "# Esempio di utilizzo\n",
    "\n",
    "# viterbi_path = Viterbi(emission_prob, transition_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione del sub-dataset di probabilità di emissione per le parole di una frase.\n",
    "\n",
    "Applicazione di diverse tecniche di smoothing per gestire le parole sconosciute:\n",
    "\n",
    "1 - Sempre O: P(unk|O) = 1\n",
    "\n",
    "2 - Sempre O o MISC: P(unk|O)=P(unk|B-MISC)=0.5\n",
    "\n",
    "3 - Uniforme: P(unk|tag) = 1/#(NER_TAGs)\n",
    "\n",
    "4 - Statistica TAG sul val set: parole che compaiono 1 sola volta  -> unknown_prob calcolata nel file learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percorso Viterbi: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "Coppie parola-tag assegnate: [('The', 'O'), ('PAROLASCONOSCIUTA', 'O'), ('tour', 'O'), ('would', 'O'), ('cover', 'O'), ('the', 'O'), ('United', 'B-LOC'), ('States', 'O'), ('and', 'O'), ('the', 'O'), ('UK', 'B-LOC'), ('and', 'O'), ('Ireland', 'B-LOC'), ('throughout', 'O'), ('2019', 'O'), ('.', 'O')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('PAROLASCONOSCIUTA', 'O'),\n",
       " ('tour', 'O'),\n",
       " ('would', 'O'),\n",
       " ('cover', 'O'),\n",
       " ('the', 'O'),\n",
       " ('United', 'B-LOC'),\n",
       " ('States', 'O'),\n",
       " ('and', 'O'),\n",
       " ('the', 'O'),\n",
       " ('UK', 'B-LOC'),\n",
       " ('and', 'O'),\n",
       " ('Ireland', 'B-LOC'),\n",
       " ('throughout', 'O'),\n",
       " ('2019', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prende in input una frase, le probabilità di emisione e transizione apprese \n",
    "#restituisce le coppie parola-NER_TAG assegnate utilizzano l'algoritmo di Viterbi e applicando la tecnica di smoothing specificata\n",
    "def viterbi_tagger(sentence, emission_prob, transition_prob, smoothing_type=1):\n",
    "    #inizializzazione\n",
    "    tags=transition_prob.keys()\n",
    "    words = sentence.split()\n",
    "    transition_df = pd.DataFrame.from_dict(transition_prob)\n",
    "    emission_sentence_df = pd.DataFrame(columns=words,index=tags)\n",
    "    \n",
    "    #iterazione per ogni parola delle frase aggiorna il dataframe delle emissioni\n",
    "    for word in words:\n",
    "        if word in emission_prob:\n",
    "            emission_sentence_df[word] = emission_prob[word].values()\n",
    "        else: #applicazione dello smoothing\n",
    "            if (smoothing_type==1): emission_sentence_df[word] =  {tag: 1 if tag == \"O\" else 0 for tag in tags}\n",
    "            elif (smoothing_type==2): emission_sentence_df[word] =  {tag: 0.5 if tag == \"B-MISC\" or tag == \"O\" else 0 for tag in tags}\n",
    "            elif (smoothing_type==3): emission_sentence_df[word] =  {tag: 1/len(tags) for tag in tags}\n",
    "            elif (smoothing_type==4): emission_sentence_df[word] =  unkown_prob\n",
    "   \n",
    "    return Viterbi(emission_sentence_df, transition_df)\n",
    "\n",
    "# Esempio di utilizzo\n",
    "sentence = \"The PAROLASCONOSCIUTA tour would cover the United States and the UK and Ireland throughout 2019 .\"\n",
    "viterbi_tagger(sentence,emission_prob,transition_prob,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TLNenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
