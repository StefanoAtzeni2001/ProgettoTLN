{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni di Gestione files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "from conllu import parse, TokenList # type: ignore\n",
    "\n",
    "#deserialize data from a file\n",
    "def load_data(file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file = open(path, 'rb') \n",
    "        data = pickle.load(file) \n",
    "        return data\n",
    "    except: \n",
    "        print(\"Error in reading data\")\n",
    "\n",
    "\n",
    "# function to read data from file\n",
    "def read_dataset(file_name,language):\n",
    "    path=\"../data/\"+language+\"/dataset/\"+file_name+\".conllu\"\n",
    "    data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Funzione per salvare il DataFrame in un file CoNLL-U\n",
    "def save_to_conllu(dataframe,file_name,language):\n",
    "    # Creazione della lista di token da DataFrame\n",
    "    path=\"../data/\"+language+\"/tagging/\"+file_name\n",
    "    tokens = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        token = {\n",
    "            \"id\": row['POSITION'],\n",
    "            \"form\": row['WORD'],\n",
    "            \"misc\":  row['TAG']\n",
    "        }\n",
    "        tokens.append(token)\n",
    "    \n",
    "    # Creazione dell'oggetto TokenList\n",
    "    token_list = TokenList(tokens)\n",
    "    \n",
    "    # Scrittura del TokenList nel file CoNLL-U\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(token_list.serialize())\n",
    "    print(\"DataFrame salvato in formato CoNLL-U:\", path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni di manipolazione e creazione del golden system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_from_dataframe(df):\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        position = row['POSITION']\n",
    "        if position == 0 and current_sentence:  # Se è il primo elemento di una nuova frase e c'è una frase in corso\n",
    "            sentences.append(' '.join([str(word) for word in current_sentence]))  # Aggiungi la frase corrente alla lista delle frasi\n",
    "            current_sentence = []  # Inizia una nuova frase\n",
    "        \n",
    "        current_sentence.append(row['WORD'])  # Aggiungi la parola corrente alla frase in corso\n",
    "\n",
    "    # Aggiungi l'ultima frase alla lista delle frasi se presente\n",
    "    if current_sentence:\n",
    "        sentences.append(' '.join([word for word in current_sentence]))\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViTerbi per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_per_sentence(emission_df, transition_df, sentences):\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Dividi la frase in parole\n",
    "        words = sentence.split()\n",
    "\n",
    "        # Numero di stati\n",
    "        num_states = len(transition_df)\n",
    "\n",
    "        # Inizializzazione della matrice di probabilità\n",
    "        dp = pd.DataFrame(index=range(num_states), columns=range(len(words)))\n",
    "        pi = 1 / num_states  # Probabilità iniziale equiprobabile\n",
    "        dp.iloc[:, 0] = np.log(pi) + np.log(emission_df.iloc[:, 0] + 1e-10)\n",
    "\n",
    "        # Inizializzazione del percorso ottimale\n",
    "        path = {state: [state] for state in range(num_states)}\n",
    "\n",
    "        # Ciclo attraverso le osservazioni\n",
    "        for t in range(1, len(words)):\n",
    "            new_path = {}\n",
    "\n",
    "            # Ciclo attraverso i possibili stati\n",
    "            for state in range(num_states):\n",
    "                # Calcolo della probabilità massima\n",
    "                max_prob = float('-inf')\n",
    "                max_state = None\n",
    "                for prev_state in range(num_states):\n",
    "                    prob = dp.iloc[prev_state, t - 1] + np.log(transition_df.iloc[state, prev_state] + 1e-10) + np.log(emission_df.iloc[state, t] + 1e-10)\n",
    "                    if prob > max_prob:\n",
    "                        max_prob = prob\n",
    "                        max_state = prev_state\n",
    "\n",
    "                dp.iloc[state, t] = max_prob\n",
    "\n",
    "                # Aggiornamento del percorso ottimale\n",
    "                new_path[state] = path[max_state] + [state]\n",
    "\n",
    "            path = new_path\n",
    "\n",
    "        # Ritorno del percorso ottimale\n",
    "        max_prob = dp.iloc[:, len(words) - 1].max()\n",
    "        max_path = path[dp.iloc[:, len(words) - 1].idxmax()]\n",
    "    \n",
    "        sentence_result = pd.DataFrame({'POSITION': range(len(max_path)), 'WORD': words, 'TAG': [emission_df.index[state] for state in max_path]})\n",
    "        results.append(sentence_result)\n",
    "        \n",
    "        # Stampa a schermo il percorso di Viterbi\n",
    "       # print('Il percorso di Viterbi è:', ' -> '.join(emission_df.index[max_path]))\n",
    "        \n",
    "    final_result = pd.concat(results)\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementazione dell'algoritmo di viterbi con la prevenzione dell'underflow tramite logaritmo e probabilità iniziale omogenea\n",
    "\n",
    "def viterbi(emission_df, transition_df):\n",
    "    # Numero di stati\n",
    "    num_states = len(transition_df)\n",
    "\n",
    "    # Inizializzazione della matrice di probabilità\n",
    "    dp = pd.DataFrame(index=range(num_states), columns=range(len(emission_df.columns)))\n",
    "    pi = 1 / num_states #Probabilità iniziale equiprobabile\n",
    "    dp.iloc[:, 0] = np.log(pi) + np.log(emission_df.iloc[:, 0] + 1e-10)\n",
    "\n",
    "    # Inizializzazione del percorso ottimale\n",
    "    path = {state: [state] for state in range(num_states)}\n",
    "\n",
    "    # Ciclo attraverso le osservazioni\n",
    "    for t in range(1, len(emission_df.columns)):\n",
    "        new_path = {}\n",
    "\n",
    "        # Ciclo attraverso i possibili stati\n",
    "        for state in range(num_states):\n",
    "            # Calcolo della probabilità massima\n",
    "            max_prob = float('-inf')\n",
    "            max_state = None\n",
    "            for prev_state in range(num_states):\n",
    "                prob = dp.iloc[prev_state, t-1] + np.log(transition_df.iloc[state, prev_state] + 1e-10) + np.log(emission_df.iloc[state, t] + 1e-10)\n",
    "                if prob > max_prob:\n",
    "                    max_prob = prob\n",
    "                    max_state = prev_state\n",
    "            \n",
    "            dp.iloc[state, t] = max_prob\n",
    "\n",
    "            # Aggiornamento del percorso ottimale\n",
    "            new_path[state] = path[max_state] + [state]\n",
    "\n",
    "        path = new_path\n",
    "\n",
    "    # Ritorno del percorso ottimale\n",
    "    max_prob = dp.iloc[:, len(emission_df.columns)-1].max()\n",
    "    max_path = path[dp.iloc[:, len(emission_df.columns)-1].idxmax()]\n",
    "\n",
    "    # Stampa a schermo il percorso di Viterbi\n",
    "    #print('Il percorso di Viterbi è:', ' -> '.join(emission_df.index[max_path]))\n",
    "\n",
    "    return pd.DataFrame({'POSITION': range(len(max_path)), 'WORD': emission_df.columns, 'TAG': [emission_df.index[state] for state in max_path]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione del sub-dataset di probabilità di emissione per le parole di una frase.\n",
    "\n",
    "Applicazione di diverse tecniche di smoothing per gestire le parole sconosciute:\n",
    "\n",
    "1 - Sempre O: P(unk|O) = 1\n",
    "\n",
    "2 - Sempre O o MISC: P(unk|O)=P(unk|B-MISC)=0.5\n",
    "\n",
    "3 - Uniforme: P(unk|tag) = 1/#(NER_TAGs)\n",
    "\n",
    "4 - Statistica TAG sul val set: parole che compaiono 1 sola volta  -> unknown_prob calcolata nel file learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prende in input una frase, le probabilità di emisione e transizione apprese \n",
    "#restituisce le coppie parola-NER_TAG assegnate utilizzano l'algoritmo di Viterbi e applicando la tecnica di smoothing specificata\n",
    "def viterbi_tagger(sentences, emission_prob, transition_prob, unkown_prob, smoothing_type, viterbi_type):\n",
    "    #inizializzazione\n",
    "    tags=transition_prob.keys()\n",
    "    transition_df = pd.DataFrame.from_dict(transition_prob)\n",
    "    emission_final_df = pd.DataFrame()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "     words = sentence.split()\n",
    "     emission_sentence_df = pd.DataFrame(columns=words,index=tags)\n",
    "     \n",
    "\n",
    "     for word in words:\n",
    "        if word in emission_prob:\n",
    "            \n",
    "            emission_sentence_df[word] = pd.Series(emission_prob[word]).values\n",
    "\n",
    "        else: #applicazione dello smoothing\n",
    "           if (smoothing_type==1): emission_sentence_df[word] =  {tag: 1 if tag == \"O\" else 0 for tag in tags}\n",
    "           elif (smoothing_type==2): emission_sentence_df[word] =  {tag: 0.5 if tag == \"B-MISC\" or tag == \"O\" else 0.01 for tag in tags}\n",
    "           elif (smoothing_type==3): emission_sentence_df[word] =  {tag: 1/len(tags) for tag in tags}\n",
    "           elif (smoothing_type==4): emission_sentence_df[word] =  unkown_prob\n",
    "     \n",
    "     emission_final_df=pd.concat([emission_final_df, emission_sentence_df], axis=1)\n",
    "    #print(emission_final_df) # matrice di emissione completa dell'intero testo posto\n",
    "    #iterazione per ogni parola delle frase aggiorna il dataframe delle emissioni\n",
    "    \n",
    "   \n",
    "    if(viterbi_type==0):   \n",
    "     return viterbi(emission_final_df, transition_df)\n",
    "    else:\n",
    "       \n",
    "       return viterbi_per_sentence(emission_final_df, transition_df, sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE TAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive tagger --> utilizza la probabilità di emissione più alta, se parola sconosciuta --> B-MISC\n",
    "\n",
    "def naive_tagger(sentences, emission_prob):\n",
    " \n",
    " tags = []\n",
    " final_df = pd.DataFrame()\n",
    "\n",
    " for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    tags = []\n",
    "    for word in words:\n",
    "        if word in emission_prob:\n",
    "            tags.append(max(emission_prob[word], key=emission_prob[word].get))\n",
    "        else:\n",
    "            tags.append(\"B-MISC\")\n",
    "    \n",
    "    # Creazione del DataFrame\n",
    "    df = pd.DataFrame({'WORD': words, 'TAG': tags})\n",
    "    df['POSITION'] = df.index  # Aggiunge la colonna POSITION\n",
    "    df = df[['POSITION', 'WORD', 'TAG']]  # Riordina le colonne\n",
    "\n",
    "    final_df=pd.concat([final_df, df], axis=0)  \n",
    "    \n",
    " return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio di Decoding Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in [\"en\",\"it\",\"es\"]:\n",
    "\n",
    " print( \"inizio lingua: \"+language) \n",
    " emission_prob=load_data(\"emission_prob\",language)\n",
    " transition_prob=load_data(\"transition_prob\",language)\n",
    " unkown_prob=load_data(\"unknown_prob\",language)\n",
    "\n",
    " #carico il file di test, estraggo la sentence e pongo il test set df come golden_df\n",
    " golden_tot = read_dataset(\"test\",language)\n",
    " golden_df = golden_tot.head(20000)\n",
    " sentence = extract_sentences_from_dataframe(golden_df)\n",
    " #print(sentence)\n",
    " vit_df=viterbi_tagger(sentence,emission_prob,transition_prob,unkown_prob,2,0)\n",
    " sent_vit_df=viterbi_tagger(sentence,emission_prob,transition_prob,unkown_prob,2,1)\n",
    "\n",
    " nayve_df=naive_tagger(sentence, emission_prob)\n",
    "\n",
    " save_to_conllu(golden_df, \"golden_tag.conllu\", language)\n",
    " save_to_conllu(vit_df, \"viterbi_tag.conllu\", language)\n",
    " save_to_conllu(nayve_df, \"nayve_tag.conllu\", language)\n",
    " save_to_conllu(sent_vit_df, \"sent_viterbi_tag.conllu\", language)\n",
    " print( \"fine lingua: \"+language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def convert_to_percentage_and_plot(emission_prob, transition_prob):\n",
    "\n",
    "    emission_df = pd.DataFrame(emission_prob,)\n",
    "    transition_df = pd.DataFrame(transition_prob)\n",
    "        # Conversione in percentuali\n",
    "    def to_percentage(df):\n",
    "        return df.div(df.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    emission_perc = to_percentage(emission_df)\n",
    "    transition_perc = to_percentage(transition_df)\n",
    "\n",
    "    # Plotting delle matrici\n",
    "    def plot_heatmap(df, title):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(df, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar=True)\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Stati attuali')\n",
    "        plt.ylabel('Stati successivi')\n",
    "        plt.show()\n",
    "\n",
    "    # Plot delle matrici\n",
    "    #plot_heatmap(emission_perc, \"Matrice di Emissione in Percentuali\")\n",
    "    plot_heatmap(transition_perc, \"Matrice di Transizione in Percentuali\")\n",
    "\n",
    "    return emission_perc, transition_perc\n",
    "\n",
    "\n",
    "# Chiamata alla funzione\n",
    "emission_perc, transition_perc = convert_to_percentage_and_plot(emission_prob, transition_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TLNenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
