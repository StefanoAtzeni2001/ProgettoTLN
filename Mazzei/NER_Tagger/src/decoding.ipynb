{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione di importazione file probabilità e dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#deserialize data from a file\n",
    "def load_data(file_name,language):\n",
    "    path=\"../data/\"+language+\"/\"+file_name\n",
    "    try: \n",
    "        file = open(path, 'rb') \n",
    "        data = pickle.load(file) \n",
    "        return data\n",
    "    except: \n",
    "        print(\"Error in reading data\")\n",
    "\n",
    "\n",
    "# function to read data from file\n",
    "def read_dataset(file_name,language):\n",
    "    path=\"../data/\"+language+\"/dataset/\"+file_name+\".conllu\"\n",
    "    data = pd.read_csv (path, sep = '\\t',quoting=3, names=[\"POSITION\",\"WORD\",\"TAG\"])\n",
    "    return data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzione di salvataggio tagging in formato conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse, TokenList\n",
    "\n",
    "# Funzione per salvare il DataFrame in un file CoNLL-U\n",
    "def save_to_conllu(dataframe,file_name,language):\n",
    "    # Creazione della lista di token da DataFrame\n",
    "    path=\"../data/\"+language+\"/tagging/\"+file_name\n",
    "    tokens = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        token = {\n",
    "            \"id\": row['POSITION'],\n",
    "            \"form\": row['WORD'],\n",
    "            \"misc\":  row['TAG']\n",
    "        }\n",
    "        tokens.append(token)\n",
    "    \n",
    "    # Creazione dell'oggetto TokenList\n",
    "    token_list = TokenList(tokens)\n",
    "    \n",
    "    # Scrittura del TokenList nel file CoNLL-U\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(token_list.serialize())\n",
    "    print(\"DataFrame salvato in formato CoNLL-U:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni di manipolazione e creazione del golden system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences_from_dataframe(df):\n",
    "    sentences = ''\n",
    "    for index, row in df.iterrows():\n",
    "        word = row['WORD']\n",
    "        if pd.notnull(word):  # Se la parola non è nulla\n",
    "            if sentences:  # Se c'è già una frase, aggiungi uno spazio prima della nuova parola\n",
    "                sentences += ' '\n",
    "            sentences += word\n",
    "    return sentences\n",
    "\n",
    "\n",
    "\n",
    "def create_golden_dataframe(sentence, golden_tag):\n",
    "    # Dividi la frase e i tag dorati in parole e tag\n",
    "    words = sentence.split()\n",
    "    tags = golden_tag.split(',')\n",
    "    \n",
    "    # Controlla se il numero di parole e tag è lo stesso\n",
    "    if len(words) != len(tags):\n",
    "        raise ValueError(\"Il numero di parole e tag dorati non corrisponde.\")\n",
    "\n",
    "    # Creazione del DataFrame dorato\n",
    "    df = pd.DataFrame({'WORD': words, 'TAG': tags})\n",
    "    df['POSITION'] = df.index + 1  # Aggiunge la colonna POSITION\n",
    "    df = df[['POSITION', 'WORD', 'TAG']]  # Riordina le colonne\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Esempio di utilizzo\n",
    "#sentence = \"In 1975 , the Princess was listed among women with whom actor Warren Beatty had had romantic relationships .\"\n",
    "#golden_tag = \"O,O,O,O,O,O,O,O,O,O,O,O,B-PER,I-PER,O,O,O,O,O\"\n",
    "#print(golden_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per l'algoritmo di Viterbi: prende in input le probabilità di emissione e di transizione sottoforma di dataframe\n",
    "# e restituisce le coppie parola-NER_TAG assegnate\n",
    "import pandas as pd\n",
    "\n",
    "def Viterbi(emission_dataframe, transition_dataframe):\n",
    "    epsilon = 1e-10  # Valore molto piccolo\n",
    "    # Lista delle parole nel testo\n",
    "    testo_array = emission_dataframe.columns.tolist()\n",
    "    # Numero di stati (tag)\n",
    "    K = transition_dataframe.shape[0]\n",
    "    \n",
    "    # Lunghezza del testo\n",
    "    T = len(testo_array)\n",
    "    \n",
    "    # Inizializzazione\n",
    "    viterbi = np.zeros((K, T))\n",
    "    backpointer = np.zeros((K, T), dtype=int)\n",
    "    \n",
    "    # Inizializzazione del primo passo\n",
    "    Pi = 1  # Start equiprobabile \n",
    "    viterbi[:, 0] = np.log(emission_dataframe.iloc[:, 0] + epsilon) + np.log(Pi)\n",
    "    backpointer[:, 0] = 0 \n",
    "    \n",
    "    # Iterazione\n",
    "    for t in range(1, T):\n",
    "        for k in range(K):\n",
    "            # Calcolo della probabilità Viterbi per ogni stato\n",
    "            max_val = float('-inf')\n",
    "            max_idx = 0\n",
    "            for j in range(K):\n",
    "                val = viterbi[j, t - 1] + np.log(transition_dataframe.iloc[j, k] + epsilon) + np.log(emission_dataframe.iloc[k, t] + epsilon)\n",
    "                if val > max_val:\n",
    "                    max_val = val\n",
    "                    max_idx = j\n",
    "            viterbi[k, t] = max_val\n",
    "            backpointer[k, t] = max_idx\n",
    "    \n",
    "    # Terminazione: Trova il massimo della colonna finale\n",
    "    max_final_val = np.max(viterbi[:, T - 1])\n",
    "    max_final_idx = np.argmax(viterbi[:, T - 1])\n",
    "    \n",
    "    # Costruzione del percorso Viterbi partendo dall'ultimo passo\n",
    "    viterbi_path = [max_final_idx]\n",
    "    for i in reversed(range(1, T)):\n",
    "        viterbi_path.insert(0, backpointer[viterbi_path[0], i])\n",
    "    \n",
    "    # Costruzione delle coppie parola-tag assegnate\n",
    "    word_tag_pairs = [(testo_array[i], transition_dataframe.index[j]) for i, j in enumerate(viterbi_path)]\n",
    "    \n",
    "    # Stampa del percorso Viterbi e delle coppie parola-tag assegnate\n",
    "    print(\"Percorso Viterbi:\", viterbi_path)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'POSITION': range(1, T + 1),\n",
    "        'WORD': [pair[0] for pair in word_tag_pairs],\n",
    "        'TAG': [pair[1] for pair in word_tag_pairs]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione del sub-dataset di probabilità di emissione per le parole di una frase.\n",
    "\n",
    "Applicazione di diverse tecniche di smoothing per gestire le parole sconosciute:\n",
    "\n",
    "1 - Sempre O: P(unk|O) = 1\n",
    "\n",
    "2 - Sempre O o MISC: P(unk|O)=P(unk|B-MISC)=0.5\n",
    "\n",
    "3 - Uniforme: P(unk|tag) = 1/#(NER_TAGs)\n",
    "\n",
    "4 - Statistica TAG sul val set: parole che compaiono 1 sola volta  -> unknown_prob calcolata nel file learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prende in input una frase, le probabilità di emisione e transizione apprese \n",
    "#restituisce le coppie parola-NER_TAG assegnate utilizzano l'algoritmo di Viterbi e applicando la tecnica di smoothing specificata\n",
    "def viterbi_tagger(sentence, emission_prob, transition_prob, unkown_prob, smoothing_type=1):\n",
    "    #inizializzazione\n",
    "    tags=transition_prob.keys()\n",
    "    words = sentence.split()\n",
    "    transition_df = pd.DataFrame.from_dict(transition_prob)\n",
    "    emission_sentence_df = pd.DataFrame(columns=words,index=tags)\n",
    "    \n",
    "    #iterazione per ogni parola delle frase aggiorna il dataframe delle emissioni\n",
    "    for word in words:\n",
    "        if word in emission_prob:\n",
    "            #\n",
    "            # Da Controllare Qui, sembra dia delle percentuali errate\n",
    "            #\n",
    "            emission_sentence_df[word] =  pd.Series(emission_prob[word]).iloc[:]\n",
    "\n",
    "        else: #applicazione dello smoothing\n",
    "           if (smoothing_type==1): emission_sentence_df[word] =  {tag: 0.99 if tag == \"O\" else 0.01 for tag in tags}\n",
    "           elif (smoothing_type==2): emission_sentence_df[word] =  {tag: 0.5 if tag == \"B-MISC\" or tag == \"O\" else 0.01 for tag in tags}\n",
    "           elif (smoothing_type==3): emission_sentence_df[word] =  {tag: 1/len(tags) for tag in tags}\n",
    "           elif (smoothing_type==4): emission_sentence_df[word] =  unkown_prob\n",
    "   \n",
    "    return Viterbi(emission_sentence_df, transition_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE TAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def naive_tagger(sentence, emission_prob):\n",
    "    tags = []\n",
    "    words = sentence.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in emission_prob:\n",
    "            tags.append(max(emission_prob[word], key=emission_prob[word].get))\n",
    "        else:\n",
    "            tags.append(\"B-MISC\")\n",
    "    \n",
    "    # Creazione del DataFrame\n",
    "    df = pd.DataFrame({'WORD': words, 'TAG': tags})\n",
    "    df['POSITION'] = df.index + 1  # Aggiunge la colonna POSITION\n",
    "    df = df[['POSITION', 'WORD', 'TAG']]  # Riordina le colonne\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio di Decoding Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percorso Viterbi: [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "DataFrame salvato in formato CoNLL-U: ../data/it/tagging/golden_tag.conllu\n",
      "DataFrame salvato in formato CoNLL-U: ../data/it/tagging/viterbi_tag.conllu\n",
      "DataFrame salvato in formato CoNLL-U: ../data/it/tagging/nayve_tag.conllu\n"
     ]
    }
   ],
   "source": [
    "import memm_tagger\n",
    "\n",
    "emission_prob=load_data(\"emission_prob\",\"it\")\n",
    "transition_prob=load_data(\"transition_prob\",\"it\")\n",
    "unkown_prob=load_data(\"unknown_prob\",\"it\")\n",
    "\n",
    "golden_tot = read_dataset(\"test\",\"it\")\n",
    "golden_df = golden_tot.head(100)\n",
    "sentence = extract_sentences_from_dataframe(golden_df)\n",
    "\n",
    "#carico il file di test, estraggo la sentence e pongo il test set df come golden_df\n",
    "#sentence =\"Il Vermont non era ancora stato colonizzato , mentre i territori del New Hampshire e del Mane erano governati dal Massachusetts .\"\n",
    "#golden_tag = \"O,B-LOC,O,O,O,O,O,O,O,O,O,O,B-LOC,I-LOC,O,O,B-LOC,O,O,O,B-LOC,O\"\n",
    "\n",
    "#\"In 1975 , the Princess was listed among women with whom actor Warren Beatty had had romantic relationships .\"\n",
    "#\"O,O,O,O,O,O,O,O,O,O,O,O,B-PER,I-PER,O,O,O,O,O\"\n",
    "\n",
    "#golden_df = create_golden_dataframe(sentence, golden_tag)\n",
    "\n",
    "vit_df=viterbi_tagger(sentence,emission_prob,transition_prob,unkown_prob,1)\n",
    "nayve_df=naive_tagger(sentence, emission_prob)\n",
    "\n",
    "\n",
    "save_to_conllu(golden_df, \"golden_tag.conllu\", \"it\")\n",
    "save_to_conllu(vit_df, \"viterbi_tag.conllu\", \"it\")\n",
    "save_to_conllu(nayve_df, \"nayve_tag.conllu\", \"it\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TLNenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
